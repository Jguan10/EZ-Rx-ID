{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from FlagEmbedding import FlagAutoModel\n",
    "import torch\n",
    "\n",
    "embed_model = FlagAutoModel.from_finetuned('BAAI/bge-base-en-v1.5',\n",
    "                                      query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages:\",\n",
    "                                      use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mINFO\u001b[0m  ENV: Auto setting PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True' for memory saving.\n",
      "\u001b[32mINFO\u001b[0m  ENV: Auto setting CUDA_DEVICE_ORDER=PCI_BUS_ID for correctness.          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m  skip BACKEND.MARLIN for No module named 'gptqmodel_marlin_kernels'       \n",
      "\u001b[32mINFO\u001b[0m  skip BACKEND.EXLLAMA_V2 for No module named 'gptqmodel_exllamav2_kernels'\n",
      "\u001b[32mINFO\u001b[0m  skip BACKEND.EXLLAMA_V1 for No module named 'gptqmodel_exllama_kernels'  \n",
      "\u001b[32mINFO\u001b[0m  skip BACKEND.TRITON for Trying to use the triton backend, but it could not be imported. Please install triton by 'pip install gptqmodel[triton] --no-build-isolation'\n",
      "\u001b[32mINFO\u001b[0m  skip BACKEND.IPEX for <class 'Exception'>                                \n",
      "\u001b[32mINFO\u001b[0m   Kernel: Auto-selection: adding candidate `TorchQuantLinear`             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "Some weights of the model checkpoint at thesven/Mistral-7B-Instruct-v0.3-GPTQ were not used when initializing MistralForCausalLM: {'model.layers.24.mlp.down_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.0.mlp.down_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.23.mlp.down_proj.bias'}\n",
      "- This IS expected if you are initializing MistralForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MistralForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING:optimum.gptq.quantizer:Found modules on cpu/disk. Using Exllama/Exllamav2 backend requires all the modules to be on GPU. Setting `disable_exllama=True`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m  Format: Converting `checkpoint_format` from `gptq` to internal `gptq_v2`.\n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Conversion complete: 0.4672822952270508s                         \n",
      "\u001b[32mINFO\u001b[0m  Optimize: `TorchQuantLinear` compilation triggered.                      \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"thesven/Mistral-7B-Instruct-v0.3-GPTQ\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"thesven/Mistral-7B-Instruct-v0.3-GPTQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1329: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "query = \"ACETAMINOPHEN uses\"\n",
    "embed_query = embed_model.encode([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Successfully loaded faiss with AVX2 support.\n",
      "INFO:faiss:Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes.\n",
      "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "vector_store = FAISS.load_local('my_vector_store', embeddings=embed_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"pregnant\" in query.lower():\n",
    "    category = 'specific population usage'\n",
    "\n",
    "elif \"uses\" in query.lower():\n",
    "    category = 'general'\n",
    "\n",
    "else:\n",
    "    category = 'general'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='aee4e363-399e-4746-b59e-3a22251d7d02', metadata={'type': 'summary', 'category': 'general'}, page_content='Summary of ACETAMINOPHEN | Uses: Uses For the temporary relief of minor aches and pains associated with • headache • toothache • minor arthritis pain • muscular aches • common cold • menstrual cramps For the reduction of fever. and  |  and  | Reactions: '),\n",
       " Document(id='3fc85fc6-8aed-42e2-8689-745f01a9c628', metadata={'type': 'summary', 'category': 'general'}, page_content='Summary of ACETAMINOPHEN | Uses: Uses temporarily: • reduces fever • relieves minor aches and pains due to: • the common cold • flu • headache • sore throat • toothache and  |  and  | Reactions: '),\n",
       " Document(id='1f6688c3-daf1-49f7-982a-91cee986d21c', metadata={'type': 'summary', 'category': 'general'}, page_content='Summary of ACETAMINOPHEN | Uses: Uses temporarily: • reduces fever • relieves minor aches and pains due to: • the common cold • flu • headache • sore throat • toothache and  |  and  | Reactions: ')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search_by_vector(\n",
    "    embed_query[0], \n",
    "    k=3, \n",
    "    filter={\"category\": category}  \n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an expert medical assistant explaining medicine to someone without any prior knowledge. \n",
    "Use the provided context to answer the user's question accurately.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\Jason\\AppData\\Local\\Temp\\ipykernel_8504\\1602439417.py:2: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  mistral_llm = HuggingFacePipeline(\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=prompt_template, input_variables=['context', 'question'])\n",
    "mistral_llm = HuggingFacePipeline(\n",
    "    pipeline=pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=300)\n",
    ")\n",
    "\n",
    "streaming_callback = StreamingStdOutCallbackHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = prompt | mistral_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] WON'T CONVERT dequantize_weight c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\gptqmodel\\nn_modules\\qlinear\\__init__.py line 437 \n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] due to: \n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 203, in aot_dispatch_base\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py\", line 4781, in codegen_node\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cpp_kernel_proxy = CppKernelProxy(kernel_group)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py\", line 3632, in __init__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.picked_vec_isa: cpu_vec_isa.VecISA = cpu_vec_isa.pick_vec_isa()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 414, in pick_vec_isa\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     _valid_vec_isa_list: List[VecISA] = valid_vec_isa_list()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                         ^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 401, in valid_vec_isa_list\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     isa_list.extend(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 404, in <genexpr>\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                                                             ^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 142, in __bool__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 152, in __bool__impl\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.check_build(VecISA._avx_code)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 102, in check_build\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 28, in _get_isa_dry_compile_fingerprint\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                               ^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 144, in get_cpp_compiler\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     check_compiler_exist_windows(compiler)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 135, in check_compiler_exist_windows\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise RuntimeError(f\"Compiler: {compiler} is not found.\") from exc\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] RuntimeError: Compiler: cl is not found.\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 203, in aot_dispatch_base\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py\", line 4781, in codegen_node\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cpp_kernel_proxy = CppKernelProxy(kernel_group)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py\", line 3632, in __init__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.picked_vec_isa: cpu_vec_isa.VecISA = cpu_vec_isa.pick_vec_isa()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 414, in pick_vec_isa\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     _valid_vec_isa_list: List[VecISA] = valid_vec_isa_list()\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                         ^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 401, in valid_vec_isa_list\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     isa_list.extend(\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 404, in <genexpr>\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                                                             ^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 142, in __bool__\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 152, in __bool__impl\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.check_build(VecISA._avx_code)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 102, in check_build\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 28, in _get_isa_dry_compile_fingerprint\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                               ^^^^^^^^^^^^^^^^^^\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 144, in get_cpp_compiler\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     check_compiler_exist_windows(compiler)\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 135, in check_compiler_exist_windows\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise RuntimeError(f\"Compiler: {compiler} is not found.\") from exc\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] RuntimeError: Compiler: cl is not found.\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0312 13:09:12.550000 8504 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mqa_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mstreaming_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m response\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3029\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3027\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3028\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3029\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3030\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3031\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:390\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    387\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    388\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 390\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    402\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:763\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    757\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    761\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    762\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 763\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:966\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    953\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    965\u001b[0m     ]\n\u001b[1;32m--> 966\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:787\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    779\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    786\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 787\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[0;32m    791\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    794\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    795\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    796\u001b[0m         )\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    798\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\langchain_community\\llms\\huggingface_pipeline.py:285\u001b[0m, in \u001b[0;36mHuggingFacePipeline._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m batch_prompts \u001b[38;5;241m=\u001b[39m prompts[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Process batch of prompts\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# Process each response in the batch\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(responses):\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:287\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1349\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1346\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1347\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1348\u001b[0m     )\n\u001b[1;32m-> 1349\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1275\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1273\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1274\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1275\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1276\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:385\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    383\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m--> 385\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ModelOutput):\n\u001b[0;32m    388\u001b[0m     generated_sequence \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msequences\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2223\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2215\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2216\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2217\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2218\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2219\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2220\u001b[0m     )\n\u001b[0;32m   2222\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2223\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2224\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2228\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2230\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2236\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2237\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2242\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2243\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3211\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   3210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[1;32m-> 3211\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   3212\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   3213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:843\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[0;32m    840\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m--> 843\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    858\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:566\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[0;32m    554\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    555\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    556\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    563\u001b[0m         position_embeddings,\n\u001b[0;32m    564\u001b[0m     )\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 566\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:247\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:162\u001b[0m, in \u001b[0;36mMistralAttention.forward\u001b[1;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    160\u001b[0m hidden_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m--> 162\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    163\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    164\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\gptqmodel\\nn_modules\\qlinear\\torch.py:151\u001b[0m, in \u001b[0;36mTorchQuantLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    149\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features,)\n\u001b[0;32m    150\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 151\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\gptqmodel\\nn_modules\\qlinear\\torch.py:159\u001b[0m, in \u001b[0;36mTorchQuantLinear._forward\u001b[1;34m(self, x, x_dtype, out_shape)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# make sure dequant dtype matches input x\u001b[39;00m\n\u001b[0;32m    157\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdequantize_weight(num_itr\u001b[38;5;241m=\u001b[39mnum_itr)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 159\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(out_shape)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     out\u001b[38;5;241m.\u001b[39madd_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "response = qa_chain.invoke({'context' : results, 'question' : query},\n",
    "                           config={'callbacks' : [streaming_callback]})\n",
    "\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
