{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from FlagEmbedding import FlagAutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "embed_model = FlagAutoModel.from_finetuned('BAAI/bge-base-en-v1.5',\n",
    "                                      query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages:\",\n",
    "                                      use_fp16=True,\n",
    "                                      devices='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m  skip BACKEND.MARLIN for No module named 'gptqmodel_marlin_kernels'       \n",
      "\u001b[32mINFO\u001b[0m  skip BACKEND.EXLLAMA_V2 for No module named 'gptqmodel_exllamav2_kernels'\n",
      "\u001b[32mINFO\u001b[0m  skip BACKEND.EXLLAMA_V1 for No module named 'gptqmodel_exllama_kernels'  \n",
      "\u001b[32mINFO\u001b[0m  skip BACKEND.TRITON for Trying to use the triton backend, but it could not be imported. Please install triton by 'pip install gptqmodel[triton] --no-build-isolation'\n",
      "\u001b[32mINFO\u001b[0m  skip BACKEND.IPEX for <class 'Exception'>                                \n",
      "\u001b[32mINFO\u001b[0m   Kernel: Auto-selection: adding candidate `TorchQuantLinear`             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at thesven/Mistral-7B-Instruct-v0.3-GPTQ were not used when initializing MistralForCausalLM: {'model.layers.6.mlp.up_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.0.mlp.down_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.17.self_attn.k_proj.bias'}\n",
      "- This IS expected if you are initializing MistralForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MistralForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING:optimum.gptq.quantizer:Found modules on cpu/disk. Using Exllama/Exllamav2 backend requires all the modules to be on GPU. Setting `disable_exllama=True`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m  Format: Converting `checkpoint_format` from `gptq` to internal `gptq_v2`.\n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Converting GPTQ v1 to v2                                         \n",
      "\u001b[32mINFO\u001b[0m  Format: Conversion complete: 0.5460710525512695s                         \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"thesven/Mistral-7B-Instruct-v0.3-GPTQ\",\n",
    "    device_map=\"cpu\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"thesven/Mistral-7B-Instruct-v0.3-GPTQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "query = \"ACETAMINOPHEN uses\"\n",
    "embed_query = embed_model.encode([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Successfully loaded faiss with AVX2 support.\n",
      "INFO:faiss:Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes.\n",
      "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "vector_store = FAISS.load_local('my_vector_store', embeddings=embed_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"pregnant\" in query.lower():\n",
    "    category = 'specific population usage'\n",
    "\n",
    "elif \"uses\" in query.lower():\n",
    "    category = 'general'\n",
    "\n",
    "else:\n",
    "    category = 'general'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='aee4e363-399e-4746-b59e-3a22251d7d02', metadata={'type': 'summary', 'category': 'general'}, page_content='Summary of ACETAMINOPHEN | Uses: Uses For the temporary relief of minor aches and pains associated with • headache • toothache • minor arthritis pain • muscular aches • common cold • menstrual cramps For the reduction of fever. and  |  and  | Reactions: '),\n",
       " Document(id='3fc85fc6-8aed-42e2-8689-745f01a9c628', metadata={'type': 'summary', 'category': 'general'}, page_content='Summary of ACETAMINOPHEN | Uses: Uses temporarily: • reduces fever • relieves minor aches and pains due to: • the common cold • flu • headache • sore throat • toothache and  |  and  | Reactions: '),\n",
       " Document(id='1f6688c3-daf1-49f7-982a-91cee986d21c', metadata={'type': 'summary', 'category': 'general'}, page_content='Summary of ACETAMINOPHEN | Uses: Uses temporarily: • reduces fever • relieves minor aches and pains due to: • the common cold • flu • headache • sore throat • toothache and  |  and  | Reactions: ')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_store.similarity_search_by_vector(\n",
    "    embed_query[0], \n",
    "    k=3, \n",
    "    filter={\"category\": category}  \n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an expert medical assistant explaining medicine to someone without any prior knowledge. \n",
    "Use the provided context to answer the user's question accurately.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\Jason\\AppData\\Local\\Temp\\ipykernel_10188\\434339248.py:2: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  mistral_llm = HuggingFacePipeline(\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=prompt_template, input_variables=['context', 'question'])\n",
    "mistral_llm = HuggingFacePipeline(\n",
    "    pipeline=pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = LLMChain(llm=mistral_llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] WON'T CONVERT dequantize_weight c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\gptqmodel\\nn_modules\\qlinear\\__init__.py line 437 \n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] due to: \n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 203, in aot_dispatch_base\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py\", line 4781, in codegen_node\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cpp_kernel_proxy = CppKernelProxy(kernel_group)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py\", line 3632, in __init__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.picked_vec_isa: cpu_vec_isa.VecISA = cpu_vec_isa.pick_vec_isa()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 414, in pick_vec_isa\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     _valid_vec_isa_list: List[VecISA] = valid_vec_isa_list()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                         ^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 401, in valid_vec_isa_list\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     isa_list.extend(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 404, in <genexpr>\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                                                             ^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 142, in __bool__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 152, in __bool__impl\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.check_build(VecISA._avx_code)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 102, in check_build\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 28, in _get_isa_dry_compile_fingerprint\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                               ^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 144, in get_cpp_compiler\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     check_compiler_exist_windows(compiler)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 135, in check_compiler_exist_windows\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise RuntimeError(f\"Compiler: {compiler} is not found.\") from exc\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] RuntimeError: Compiler: cl is not found.\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1164, in __call__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 547, in __call__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 986, in _compile\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 715, in compile_inner\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_utils_internal.py\", line 95, in wrapper_function\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 750, in _compile_inner\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 231, in _fn\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 662, in transform\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     tracer.run()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2868, in run\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     super().run()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1052, in run\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     while self.step():\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 962, in step\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self._return(inst)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3033, in _return\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1101, in compile_subgraph\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1432, in call_user_compiler\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 130, in __call__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\__init__.py\", line 2340, in __call__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1863, in compile_fx\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return aot_autograd(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 83, in __call__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 203, in aot_dispatch_base\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 489, in __call__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return inner_compile(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 102, in debug_wrapper\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2027, in compile_to_module\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2033, in _compile_to_module\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1968, in codegen\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.scheduler.codegen()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3477, in codegen\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self._codegen()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3554, in _codegen\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.get_backend(device).codegen_node(node)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py\", line 4781, in codegen_node\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     cpp_kernel_proxy = CppKernelProxy(kernel_group)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py\", line 3632, in __init__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     self.picked_vec_isa: cpu_vec_isa.VecISA = cpu_vec_isa.pick_vec_isa()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 414, in pick_vec_isa\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     _valid_vec_isa_list: List[VecISA] = valid_vec_isa_list()\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                         ^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 401, in valid_vec_isa_list\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     isa_list.extend(\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 404, in <genexpr>\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                                                             ^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 142, in __bool__\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 152, in __bool__impl\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     return self.check_build(VecISA._avx_code)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 102, in check_build\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 28, in _get_isa_dry_compile_fingerprint\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]                                               ^^^^^^^^^^^^^^^^^^\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 144, in get_cpp_compiler\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     check_compiler_exist_windows(compiler)\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]   File \"c:\\Users\\Jason\\Documents\\GitHub\\EZ-Rx-ID\\.venv\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 135, in check_compiler_exist_windows\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233]     raise RuntimeError(f\"Compiler: {compiler} is not found.\") from exc\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] RuntimeError: Compiler: cl is not found.\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0312 03:49:10.014000 10188 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1233] \n"
     ]
    }
   ],
   "source": [
    "response = qa_chain.invoke({'context' : results, 'question' : query})\n",
    "\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
